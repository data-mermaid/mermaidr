---
title: "WCS Vibrant Oceans Baseline Coral Reef Monitoring"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{WCS Vibrant Oceans Baseline Coral Reef Monitoring}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  dpi = 300,
  message = FALSE,
  warning = FALSE,
  fig.path = "vo-"
)

options(tibble.max_extra_cols = 20)
```

This case study follows an analysis of baseline coral reef studies for Vibrant Oceans, completed by the Wildlife Conservation Society (WCS). The original survey and analysis covered 168 sites across Tanzania, Fiji, and Indonesia, surveying underwater information across a diversity of management, habitat types, and other environmental characteristics. This analysis is a small subset, only using publicly available data, and intended to illustrate the usage of `mermaidr` for such a project.

First, we load `mermaidr` and search for projects tagged with "Vibrant Oceans":

```{r}
library(mermaidr)

vo_projects <- mermaid_search_projects(tags = "Vibrant Oceans")

vo_projects
```

For this analysis, WCS field teams accessed ecological condition using underwater surveys to assess two key indicators of coral reef health: live hard coral cover and reef fish biomass. This data is available from `mermaidr` via the benthic PIT and fishbelt methods, respectively. We'll focus on projects that have summary data publicly available for these methods.

We are able to see the data policy of projects and methods by looking at the `data_policy_*` columns of `vo_projects`. For example, focusing on benthic PIT and fishbelt, we can see that the Taka Bonerate NP-2019 project has summary data publicly available for fishbelt and benthic PIT, while the 2019 Dama Bureta Waibula and Dawasamu-WISH ecological survey has public data available for only benthic PIT.

```{r}
library(tidyverse)

vo_projects %>%
  select(name, data_policy_beltfish, data_policy_benthicpit)
```

# Live hard coral cover

We'll focus on hard coral (benthic PIT) data first. We can get this data by filtering for projects that have publicly available summary data for it (returning both the Taka Bonerate and Dama Bureta Waibula and Dawasamu projects):

```{r}
projects_public_benthic <- vo_projects %>%
  filter(data_policy_benthicpit == "Public Summary")

projects_public_benthic %>%
  select(name)
```

And then by querying for public summary data, using `mermaid_get_project_data()`, specifying the "benthicpit" method with "sampleevents" data. The key to accessing public summary data is to set our token to `NULL` - this makes it so that `mermaidr` won't try to authenticate us, and instead just returns the data *if* the data policy allows it.

```{r}
benthic_data <- projects_public_benthic %>%
  mermaid_get_project_data("benthicpit", "sampleevents", token = NULL)

head(benthic_data)
```

At a high level, this returns the aggregations for a survey at the *sample event* level; roughly, it provides a summary of all observations for all transects at a given site and date, giving us information like the average percent cover for each benthic category. Let's focus in on the `country`, `site`, and `percent_cover_benthic_category_avg_hard_coral` columns.

```{r}
benthic_data <- benthic_data %>%
  select(country, site, hard_coral = percent_cover_benthic_category_avg_hard_coral)
```

We'd like to summarise hard coral coverage across these sites. WCS considers a 10% cover as a minimum threshold of carbonate production and reef growth, while 30% cover may be more related to a threshold for biodiversity and fisheries production, so we will aggregate and visualize the coverage.

First, let's categorize each value of `hard_coral` according to whether it's below 10%, between 10% and 30%, or above 30%:

```{r}
benthic_data <- benthic_data %>%
  mutate(threshold = case_when(
    hard_coral < 10 ~ "Below 10% cover",
    hard_coral >= 10 & hard_coral < 30 ~ "Midrange 10-30% cover",
    hard_coral >= 30 ~ "Above 30% hard coral cover"
  ))
```

We can count how many fall into each category - it looks like the bulk of sites (57%) fall into the midrange 10 - 30% cover category, a small number (8.9%) are below 10%, and about a third (34.2%) of surveyed sites have above 30% hard coral cover.

```{r}
benthic_data %>%
  count(threshold) %>%
  mutate(prop = n / sum(n))
```

We'd also like to see the distribution of these values - for example, what do those 10 - 30% coverages actually look like?

Let's visualize the data, using `ggplot2`:

```{r, fig.height = 8, fig.alt = "A bar chart with hard coral cover on the x axis (titled hard_coral) and sites on the y axis (titled site). The bars are colored in pink, green, and blue, according to whether they have above 30% hard coral cover, below 10% cover, or 10-30% cover, respectively. The sites are ordered alphabeticaly."}
library(ggplot2)

ggplot(benthic_data) +
  geom_col(aes(x = hard_coral, y = site, fill = threshold))
```

This is a good start, but it would probably be much more useful with a few changes. We can recorder the sites so that they go in descending order, from highest to lowest hard coral coverage. We can also rearrange the threshold legend, so that it follows a logical order, from highest to lowest coverage (instead of alphabetical). It would also be helpful to add a line at the 10% and 30% points, to visualize those thresholds more explicitly.

```{r, fig.height = 8, fig.alt = "A bar chart with hard coral cover on the x axis (titled hard_coral) and sites on the y axis (titled site). The bars are colored in pink, green, and blue, according to whether they have above 30% hard coral cover, 10-30% cover, or below 10% cover. The sites are ordered by their hard coral coverage, from highest to lowest. There is a dashed vertical line at 10% and 30% hard coral."}
benthic_data <- benthic_data %>%
  mutate(
    threshold = fct_reorder(threshold, hard_coral, .desc = TRUE),
    site = fct_reorder(site, hard_coral)
  )

hard_coral_plot <- ggplot(benthic_data) +
  geom_col(aes(x = hard_coral, y = site, fill = threshold), alpha = 0.8) +
  geom_vline(xintercept = 10, linetype = "dashed", size = 0.25) +
  geom_vline(xintercept = 30, linetype = "dashed", size = 0.25)

hard_coral_plot
```

Finally, we can make some visual changes, like updating the theme, removing the site names (we care more about the distribution than which site they correspond to for this plot), adding axis labels for every 10%, cleaning up labels, and some other fiddly bits to create a beautiful plot!

```{r, fig.alt = "A bar chart with hard coral cover on the x axis and sites on the y axis. The bars are colored in grey, yellow, and red, according to whether they have above 30% hard coral cover, 10-30% cover, or below 10% cover. The sites are ordered by their hard coral coverage, from highest to lowest. There is a vertical line at 10% and 30% hard coral cover. The site names have been removed and the plot now has a title: A sample of WCS Vibrant Ocean survey sites, ordered by hard coral cover. The x axis is titled: Hard coral cover, %."}
hard_coral_plot <- hard_coral_plot +
  scale_x_continuous(name = "Hard coral cover, %", breaks = seq(0, 70, 10)) +
  scale_y_discrete(name = NULL) +
  scale_fill_manual(name = "Threshold", values = c("#7F7F7F", "#F1A83B", "#E73F25")) +
  labs(title = "A sample of WCS Vibrant Oceans survey sites, ordered by hard coral cover") +
  theme_minimal() +
  theme(
    axis.text.y = element_blank(),
    panel.grid.minor = element_blank(),
    panel.grid.major.y = element_blank()
  )

hard_coral_plot
```

That looks much better!

For further analysis, we can also calculate the average hard coral cover and its standard error, then show them in a beautiful graph. To do this, first, we need to calculate the average hard coral cover and its standard error. Since the highest level in the data after site is country, in this example, we will calculate the average hard coral cover per country and treat sites as the replicates per country. We’re going to use the `ddply` function from `plyr` to calculate the average hard coral cover and its standard error.


```{r}
Library(plyr)

hc_country <- ddply(benthic_data, "country", summarise,
                    nSite = length(site),
                    avrg_hc = mean(hard_coral),
                    se_hc = sd(hard_coral)/sqrt(nSite))
```

Take a look at the `hc_country` dataframe. There are only four columns with four rows of data. You can also use the code to calculate the average hard coral cover percentage based on other columns. For example, if you want to average per management regime, you need to make sure that the column is in your data and change `country` with the column name where your management regimes are. You can also calculate the average and standard error for other benthic attribute, such as soft coral, macroalgae, etc.

Now that we’ve calculated the average hard coral cover and standard error, the next step is to put the result in a nice graph. We will do this using the `ggplot2` as we did it previously.

```{r}
avrg_hc_plot <- ggplot(hc_country, aes(x = country, y = avrg_hc, fill = country)) +
  geom_bar(stat = "identity") +
  labs(x = "Country", y = "Average Hard Coral Cover (%)") +
  guides(fill=guide_legend(title="Countries")) +
  ggtitle("Average Hard Coral Cover per Country") +
  geom_errorbar(aes(ymin = avrg_hc - se_hc, ymax = avrg_hc + se_hc), width = .2, position = position_dodge(.9)) +
  theme_classic() +
  theme(plot.title = element_text(face = "bold", hjust = 0.5))

avrg_hc_plot
```
<img src="vo-average-hard-coral-cover-per-country.png" title="A bar chart with country on the x axis and average hard coral cover on the y axis. The bars are colored in red, green, tosca, and purple, according to country. The bar chart has a standard error for each country, using site as the replicates. The plot now has a title: Average Hard Coral Cover per Country. The x axis is titled: Country and the y axis is titled: Average Hard Coral Cover (%)." />


It might also be interesting to see the changes in hard coral cover through time. To make this graph, first, we need to add the data column in our benthic data.

```{r}
benthic_data <- projects_public_benthic %>%
  mermaid_get_project_data("benthicpit", "sampleevents", token = NULL)
head(benthic_data)

benthic_data <- benthic_data %>%
  select(country, site, sample_date, hard_coral = percent_cover_benthic_category_avg_hard_coral)
```

After adding the date column, the next step is to separate it into year, month, and day. To do this, we’re going to use the `separate` function from `tidyr` package.

```{r}
Library(tidyr)

benthic_data <- benthic_data %>% separate(sample_date, into = c('Year', 'Month', 'Day'),
                                        sep = '-')
```

Now we have all of the columns that we need, we can continue by calculating the average hard coral cover per year per country.

```{r}
hc_country_year <- ddply(benthic_data, c("country", "Year"), summarise,
                         avrg_hc = mean(hard_coral))
```

In the `hc_country_year` dataframe, you can see that only `Fiji` and `Indonesia` have more than one year data. So, we’re going to remove countries that only have one year data.

```{r}
hc_country_year <- hc_country_year[c(hc_country_year=="Fiji" | hc_country_year=="Indonesia"),]
```

Now, we are ready to present the data in a line plot using the `ggplot2` package.

```{r}
avrg_hc_year_plot <- ggplot(hc_country_year, aes(x = Year, y = avrg_hc, group = country)) +
  geom_line(aes(color = country)) +
  geom_point(aes(color = country)) +
  labs(x = "Year", y = "Average Hard Coral Cover (%)") + ggtitle("Trend Average Hard Coral Cover per Country") +
  guides(color=guide_legend(title="Countries")) +
  theme_classic() +
  theme(plot.title = element_text(face = "bold", hjust = 0.5))

avrg_hc_year_plot
```
<img src="vo-trend-hc-per-country.png" title="A line chart with year on the x axis and average hard coral cover on the y axis. The lines are colored in red and blue to differentiate per country. The plot now has a title: Trend Average Hard Coral Cover per Country. The x axis is titled: Year and the y axis is titled: Average Hard Coral Cover (%)." />

Looks great! You can save the plot and use it in your report!

# Reef fish biomass

Next, let's turn to reef fish biomass. Similarly to the step above, we can get this data by filtering for projects that have publicly available summary data for it, returning only the Taka Bonerate project.

```{r}
projects_public_fishbelt <- vo_projects %>%
  filter(data_policy_beltfish == "Public Summary")

projects_public_fishbelt %>%
  select(name)
```

Next, we query for public summary data, again using `mermaid_get_project_data` to get "sampleevents" data, this time specifying the "fishbelt" method:

```{r}
fishbelt_data <- projects_public_fishbelt %>%
  mermaid_get_project_data("fishbelt", "sampleevents", token = NULL)

head(fishbelt_data)
```

Again, this summarises all observations for all transects at a given site and date, and gives us information like the average biomass at that site, and average biomass across groupings like trophic group or fish family.

We'll just focus on the average biomass:

```{r}
fishbelt_data <- fishbelt_data %>%
  select(country, site, biomass = biomass_kgha_avg)
```

WCS considers 500 kg/ha as a threshold where below this biomass, ecosystems may pass critical thresholds of ecosystem decline, and often seek to maintain reef fish biomass above 500 kg/ha as a management target. Let's categorize each value of `biomass` according to whether it's above or below 500 kg/ha, and reorder both the sites and the threshold factor from highest to lowest biomass:

```{r}
fishbelt_data <- fishbelt_data %>%
  mutate(
    threshold = case_when(
      biomass >= 500 ~ "Above 500 kg/ha",
      biomass < 500 ~ "Below 500 kg/ha"
    ),
    threshold = fct_reorder(threshold, biomass, .desc = TRUE),
    site = fct_reorder(site, biomass)
  )
```

Then, we can visualize the distribution of average biomass in sites, similar to our visualization before:

```{r, fig.alt = "A bar chart showing total reef fish biomass in kilograms per hectare (on the axis) by site (on the y axis). The sites are shown in order of their biomass, from highest to lowest. The bars are grey if the biomass is above 500 kg and red if it is below 500kg. There is a vertical dashed line at the 500kg mark. The plot is titled 'A sample of WCS Vibrant Oceans survey sites, ordered by reef fish biomass.'"}
ggplot(fishbelt_data) +
  geom_col(aes(x = biomass, y = site, fill = threshold), alpha = 0.8) +
  geom_vline(xintercept = 500, linetype = "dashed", size = 0.25) +
  scale_x_continuous(name = "Total reef fish biomass, kg/ha") +
  scale_y_discrete(name = NULL) +
  scale_fill_manual(name = "Threshold", values = c("#7F7F7F", "#E73F25")) +
  labs(title = "A sample of WCS Vibrant Oceans survey sites, ordered by reef fish biomass") +
  theme_minimal() +
  theme(
    axis.text.y = element_blank(),
    panel.grid.minor = element_blank(),
    panel.grid.major.y = element_blank()
  )
```
